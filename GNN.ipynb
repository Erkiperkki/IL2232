{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3/iHLsk9+VE6K8QafypIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erkiperkki/IL2232/blob/main/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import from_networkx\n",
        "import networkx as nx\n"
      ],
      "metadata": {
        "id": "TFudoUnorwrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f3ac9a-741e-49a6-a568-82062c428421"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSV89xyoK_wM",
        "outputId": "622ed473-4559-4f98-816f-bc2f8f1881dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH=\"/content/drive/MyDrive/Embedded Systems Design Project\"\n",
        "\n",
        "#/content/drive/MyDrive/Embedded Systems Design Project/output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "dataset=[]\n",
        "graph_list=torch.load(PATH + \"/IA_graph.csv\")\n",
        "for g in graph_list:\n",
        "  d = from_networkx(g)\n",
        "\n",
        "  nodes = g.nodes()\n",
        "  edge_index = d.edge_index\n",
        "  edge_label = d.label\n",
        "  num_nodes = d.num_nodes\n",
        "\n",
        "  data = HeteroData()\n",
        "  edge_label = torch.FloatTensor( [float(i) for i in list(edge_label)])\n",
        "  data[\"data\"].node_id = torch.IntTensor( [int(i) for i in list(nodes)])\n",
        "\n",
        "  data['data', 'edge', 'data'].edge_index = edge_index\n",
        "  data['data', 'edge', 'data'].edge_label = edge_label\n",
        "\n",
        "  dataset.append(data)\n",
        "\n",
        "  # Save node indices:\n",
        "  '''\n",
        "  data.node_id = Tensor(list(B.nodes()))\n",
        "\n",
        "  # Add the node features and edge indices:\n",
        "  data.x = np.ones(B.number_of_nodes())\n",
        "\n",
        "  data.edge_index = edge_index\n",
        "  data.edge_label = edge_label\n",
        "  data.number_of_nodes =  num_nodes\n",
        "\n",
        "  '''\n",
        "  # Add the node features and edge indices:\n",
        "  #data[\"data\"].x = np.ones(B.number_of_nodes())\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "#data = T.ToUndirected()(data)"
      ],
      "metadata": {
        "id": "YipHUM8gGeIz"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #generate fake/debugging dataset\n",
        "# dataset=[]\n",
        "# for i in range(1000):\n",
        "#   dataset.append(data)"
      ],
      "metadata": {
        "id": "pzSm8eodBgn8"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_train_samples = int(0.7*len(dataset))\n",
        "\n",
        "train_dataset = dataset[0:num_train_samples]\n",
        "test_dataset = dataset[num_train_samples:]"
      ],
      "metadata": {
        "id": "yBaEgTqEBZjl"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load graph object from file\n",
        "#d = pickle.load(open('sampled_data.pickle', 'rb'))"
      ],
      "metadata": {
        "id": "j606YjzWCJGf"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "uxkDlFTJAaR7"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_num_nodes=sum([data.num_nodes for data in dataset])"
      ],
      "metadata": {
        "id": "CUGKtBB-Dz4i"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_user[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "        #ones=torch.ones(edge_feat_user.size(), dtype=torch.long)\n",
        "        #return  (edge_feat_user * ones).sum(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "\n",
        "        #self.movie_lin = torch.nn.Linear(1, hidden_channels)\n",
        "\n",
        "        self.data_emb = torch.nn.Embedding(tot_num_nodes, hidden_channels)\n",
        "        #self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata = (['data'], [('data',\"edge\",'data')]) )\n",
        "\n",
        "        #([\"node_id\"],[\"edge_index\"])\n",
        "\n",
        "        #look here need to change metedata to all possible types\n",
        "\n",
        "        '''\n",
        "(['user', 'movie'],\n",
        " [('user', 'rates', 'movie'), ('movie', 'rev_rates', 'user')])\n",
        "\n",
        "which node representations are learned for each node type in\n",
        "metadata[0], and messages are exchanged between each edge type in\n",
        "metadata[1], as denoted in the \"Modeling Relational Data with Graph Convolutional Networks\" <https://arxiv.org/abs/1703.06103>_ paper:\n",
        "\n",
        "where x_dict and edge_index_dict denote dictionaries that\n",
        "hold node features and edge connectivity information for each node type and\n",
        "edge type, respectively.\n",
        "\n",
        "        '''\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"data\": self.data_emb(data[\"data\"].node_id),\n",
        "          #\"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
        "        }\n",
        "        #print(x_dict)\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"data\"],\n",
        "            data['data', 'edge', 'data'].edge_index\n",
        "            #data['data', 'edge', 'data'].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "#model = GNN(hidden_channels=64)\n",
        "\n",
        "print(model)\n",
        "\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data['data', 'edge', 'data'].edge_label\n",
        "\n",
        "        #print(f\"pred = {(ground_truth.type())}\")\n",
        "        #ground_truth*[1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1]\n",
        "\n",
        "        # loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "        loss = ((pred - ground_truth) ** 2).mean()\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "yVC2llbmAaUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b3bbbe-c9b4-43e1-8ac3-074dd95d33dd"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (data_emb): Embedding(88, 64)\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Classifier()\n",
            ")\n",
            "Device: 'cpu'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 176.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 3.7409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 179.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 3.7841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 168.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 3.4137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 174.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 1.0536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import roc_auc_score\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in (test_dataset):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        preds.append(model(sampled_data))\n",
        "        ground_truths.append(sampled_data[\"data\", \"edge\", \"data\"].edge_label)\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "pred=[int(p) for p in pred]\n",
        "ground_truth=[int(p) for p in ground_truth]"
      ],
      "metadata": {
        "id": "kzkLoQh6cGFU"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(ground_truth, pred, labels=[0,1,2,3,4])\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Greens');  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "ax.set_xlabel('Predicted labels');\n",
        "ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "x_labels=['LTR', 'RTL', 'MF', 'MB', 'NC']\n",
        "y_labels=x_labels\n",
        "ax.xaxis.set_ticklabels(x_labels); ax.yaxis.set_ticklabels(y_labels);\n",
        "#auc = roc_auc_score(ground_truth, pred, multi_class=\"ovo\")\n",
        "# print()\n",
        "# print(f\"Validation AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ajLewHP05io0",
        "outputId": "99efdaa2-58da-49be-aacb-cbdbbd362cc4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#not used!!!\n",
        "raise ValueError"
      ],
      "metadata": {
        "id": "zMR4BPO8G2JJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "1a021b4a-396a-450a-a102-a8b8556a9315"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-2f116213d9b2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#not used!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#try 2\n",
        "from torch_geometric.nn import GraphConv\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(-1, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 9)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        x, edge_index, batch = data[\"data\"].node_id, data[(\"data\", \"edge\", \"data\")].edge_index, data[\"data\"].batch\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        #x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = GNN(hidden_channels=64)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "3RvZ1gJnOoGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081eebae-26fe-4f28-f5ee-314f44cd0aec"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN(\n",
            "  (conv1): GCNConv(-1, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=9, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xb0SrTACUTyS"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset"
      ],
      "metadata": {
        "id": "k3RJTT7GAZHu"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index_dict\n"
      ],
      "metadata": {
        "id": "QgV7JCnL6ulh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af9da09-8673-4fad-b725-03c5d473d02f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('data',\n",
              "  'edge',\n",
              "  'data'): tensor([[0, 1],\n",
              "         [1, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=data.metadata()\n",
        "names = metadata[0] + [rel for _, rel, _ in metadata[1]]\n",
        "for name in names:\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "WjFZAht0r5N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70bf0d9-4481-4a96-87a7-0d4be78b940f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "edge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " data[\"edge\"].edge_index"
      ],
      "metadata": {
        "id": "GdPJxmmsWeNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c10b267-cd1c-438d-8869-dbae0311395e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "Ak9niIxODTeR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "09bf0051-32ee-43a8-b8d1-0432d0d98704"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cpu'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-d3fea5603d44>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msampled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rates\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"movie\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-995eba06f508>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"edge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0;32m--> 223\u001b[0;31m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7l60br3AaXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxHZP4fQAaZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBTK_1BfAabk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSVmVsohAad4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "#IG[data.edge_index[0][i].item()][2]\n",
        "print(IG[data.edge_index[0][i].item()+1][data.edge_index[1][i].item()+1])"
      ],
      "metadata": {
        "id": "ojqOb25y7o8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=from_networkx(IG)\n",
        "print(data.edge_index)\n",
        "edge_attr=[]\n",
        "for i in range(len(data.edge_index[0])):\n",
        "  print([data.edge_index[0][i]+1][0].item())\n",
        "  t=(IG[data.edge_index[0][i].item()][data.edge_index[1][i].item()])\n",
        "  print(t)\n",
        "  edge_attr.append=t\n",
        "edge_attr\n",
        "#edge_attr= [IG[] for i in data.edge_index]\n",
        "#print(edge_attr)\n",
        "\n",
        "\n",
        "'''\n",
        "edge_attr[i] corresponds to the edge\n",
        "between edge_index[0][i] and edge_index[1][i].\n",
        "'''\n"
      ],
      "metadata": {
        "id": "WoDgpsOAsF3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index=[for i in IG.edges()]\n"
      ],
      "metadata": {
        "id": "WzhVuFifq2Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install dgl\n",
        "\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qBpBTGxGdmKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "q1dvS2D_gIVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "nx.write_edgelist(B,PATH+\"/IA_graph1.csv\",data=[\"label\"], delimiter =\",\" )\n"
      ],
      "metadata": {
        "id": "-YsX82bEJNWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)\n",
        "d=from_networkx(B)\n",
        "edge_index = d.edge_index\n",
        "edge_label = d.label\n",
        "num_nodes = d.num_nodes\n"
      ],
      "metadata": {
        "id": "zSCIwjO7JO1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph=pd.read_csv(PATH + \"/IA_graph1.csv\", header=None, names=[\"src\",'dst','label'])\n",
        "graph"
      ],
      "metadata": {
        "id": "Jn_rx9oQJuEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = np.random.randint(0, 100, 500)\n",
        "dst = np.random.randint(0, 100, 500)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "edge_pred_graph.edata['feature'] = torch.randn(1000, 10)\n",
        "edge_pred_graph.edata['label'] = torch.randn(1000)\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(1000, dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SJpTKrcxq4Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph"
      ],
      "metadata": {
        "id": "dn9qon6OQCQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)"
      ],
      "metadata": {
        "id": "G_9ix10yRyxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph.num_edges()"
      ],
      "metadata": {
        "id": "lOZGUa0oU-cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "edge_pred_graph=dgl.from_networkx(B, edge_attrs=[\"label\"])\n",
        "#edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)\n",
        "edge_pred_graph.edata['train_mask']\n"
      ],
      "metadata": {
        "id": "OA_iqIKSQCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(graph))\n",
        "src = graph.src\n",
        "dst = graph.dst\n",
        "num_edges=len(graph)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "#edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "# edge_pred_graph.edata['feature'] = graph.label\n",
        "edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SO5-wmb-Itpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTP9oylYHDpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkCrIptJdbJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNrLbiorddYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWyJQyIzdiYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contruct a two-layer GNN model\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # inputs are features of nodes\n",
        "        print(graph)\n",
        "        print(inputs)\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "import dgl.function as fn\n",
        "class DotProductPredictor(nn.Module):\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, in_features, out_classes):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(in_features * 2, out_classes)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        h_u = edges.src['h']\n",
        "        h_v = edges.dst['h']\n",
        "        score = self.W(torch.cat([h_u, h_v], 1))\n",
        "        return {'score': score}\n",
        "\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(self.apply_edges)\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super().__init__()\n",
        "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
        "        self.pred = DotProductPredictor()\n",
        "    def forward(self, g, x):\n",
        "        h = self.sage(g, x)\n",
        "        return self.pred(g, h)\n",
        "\n",
        "from torch import Tensor\n",
        "# node_features = edge_pred_graph.ndata['feature']\n",
        "edge_label = edge_pred_graph.edata['label']\n",
        "train_mask = edge_pred_graph.edata['train_mask']\n",
        "model = Model(1, 20, 10)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "pred = model(edge_pred_graph, Tensor())\n",
        "loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "opt.zero_grad()\n",
        "loss.backward()\n",
        "opt.step()\n",
        "print(loss.item())\n",
        "\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     pred = model(edge_pred_graph, Tensor())\n",
        "#     loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "#     opt.zero_grad()\n",
        "#     loss.backward()\n",
        "#     opt.step()\n",
        "#     print(loss.item())"
      ],
      "metadata": {
        "id": "lX394xGDdkSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpqQ_mRqdFOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class EdgePredictor(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EdgePredictor, self).__init__(aggr='max')  # Use max pooling for message aggregation\n",
        "\n",
        "        self.node_idx = torch.arange(in_channels, dtype=torch.long)\n",
        "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x: Node features\n",
        "        # edge_index: Graph connectivity\n",
        "\n",
        "        # Add self-loops for the message passing\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Calculate the normalized degree for each node\n",
        "        deg = degree(edge_index[0], x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        # Calculate the normalized adjacency matrix\n",
        "        norm = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
        "        edge_index_norm = Tensor((2,200))\n",
        "        print((edge_index / norm).size())\n",
        "        print((edge_index).size())\n",
        "        edge_index_norm = (edge_index / norm).int\n",
        "        return self.propagate(edge_index=edge_index_norm, size=(x.size(0), x.size(0)), x=x)\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        aggr_out = torch.cat([aggr_out, x[self.node_idx]], dim=-1)\n",
        "        aggr_out = F.relu(self.lin(aggr_out))\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Initialize the model\n",
        "model = GNNEdgeClassifier(in_channels=1, hidden_channels=32, out_channels=11)  # 11 classes (0 to 10)\n",
        "\n",
        "# Example data (replace with your own data)\n",
        "x = torch.randn(100, 1)  # Node features (not used in this example)\n",
        "edge_index = torch.randint(0, 100, (2, 200), dtype=torch.long)  # Random edge connectivity\n",
        "edge_labels = torch.randint(0, 11, (200,), dtype=torch.long)  # Random edge labels (0 to 10)\n",
        "\n",
        "# Forward pass\n",
        "predictions = model(x, edge_index)\n",
        "\n",
        "# Calculate loss (replace with your own loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(predictions, edge_labels)\n"
      ],
      "metadata": {
        "id": "7QEW1FPzeS1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPioOvKCZp37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}