{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvV9vbB3clhYVO1La3b/fn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erkiperkki/IL2232/blob/main/Copy_of_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.data import HeteroData\n",
        "# import torch_geometric.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "# https://colab.research.google.com/github/Erkiperkki/IL2232/blob/main/GNN.ipynb\n",
        "\n",
        "'''\n",
        "Todoo:\n",
        "fix results to vector / Erik\n",
        "Compare with mlp\n",
        "add features from nodes /Erik\n",
        "'''"
      ],
      "metadata": {
        "id": "TFudoUnorwrj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "86ba287b-9afb-4b87-eff7-31367768d806"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTodoo:\\nfix results to vector / Erik\\nCompare with mlp\\nadd features from nodes /Erik\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSV89xyoK_wM",
        "outputId": "6716c6c2-1eac-4b71-d42c-db94648e6b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH=\"/content/drive/MyDrive/Embedded Systems Design Project\"\n",
        "NUM_EDGE_CLASSES = 5\n",
        "NUM_NODE_FEATURES = 3\n",
        "XY_SCALE_FACTOR = 1/100 # xy * scale factor to get value for IG graph\n",
        "REMOVE_ISOLETED_NODES = False\n",
        "#/content/drive/MyDrive/Embedded Systems Design Project/output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "dataset=[]\n",
        "num_static=0\n",
        "num_nonstatic=0\n",
        "graph_list=torch.load(PATH + \"/IA_graph_dataset\")\n",
        "group_edge_attrs =([\"label\"])\n",
        "group_node_attrs = ([\"xy\", \"static\"])\n",
        "\n",
        "node_type_names = ([\"data\",\"static\"])\n",
        "edge_type_names=[(\"data\",\"edge\",\"data\"), (\"data\",\"edge\",\"static\"), (\"static\",\"edge\",\"data\"), (\"static\",\"edge\",\"static\")]\n",
        "\n",
        "transform = T.Compose([T.remove_isolated_nodes.RemoveIsolatedNodes()])\n",
        "\n",
        "def get_edge_type_maping(edge_index, edge_type_names, node_types, node_types_names) -> torch.Tensor:\n",
        "  edge_type_list=[]\n",
        "  for i in range(len(d.edge_index[0])):\n",
        "    #provides the type of node as a str to src and dest\n",
        "    src =  node_type_names[node_types[d.edge_index[0][i]]]\n",
        "    dest =  node_type_names[node_types[d.edge_index[1][i]]]\n",
        "    edge_type_list.append(edge_type_names.index((src,\"edge\",dest)))\n",
        "\n",
        "  return torch.Tensor(edge_type_list).long()\n",
        "\n",
        "for g in graph_list:\n",
        "  remapped_g = nx.convert_node_labels_to_integers(g, first_label=0, label_attribute=\"yolo_object_id\") #remaps the ndes (and edges) to format like 0,1,2...N\n",
        "  d = from_networkx(remapped_g, group_node_attrs= group_node_attrs, group_edge_attrs= group_edge_attrs)\n",
        "  if(REMOVE_ISOLETED_NODES and d.has_isolated_nodes()):\n",
        "    d = transform(d)\n",
        "\n",
        "  d.x[:,[1]]=d.x[:,[1]] * XY_SCALE_FACTOR\n",
        "  d.x[:,[0]]=d.x[:,[0]] * XY_SCALE_FACTOR\n",
        "  node_types=(d.x[:,2]).long()\n",
        "  edge_type = get_edge_type_maping(d.edge_index, edge_type_names, node_types, node_type_names)\n",
        "\n",
        "  hd = d.to_heterogeneous(node_type=node_types, edge_type=edge_type, node_type_names=node_type_names, edge_type_names=edge_type_names)\n",
        "  hd[\"data\"].node_id = torch.IntTensor( [i for i,x in enumerate(node_types) if node_type_names[x] == \"data\"] )\n",
        "  hd[\"static\"].node_id =torch.IntTensor( [i for i,x in enumerate(node_types) if node_type_names[x] == \"static\"] )\n",
        "\n",
        "  dataset.append(hd)\n"
      ],
      "metadata": {
        "id": "v0HwzTvUFpFY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "max_num_data_nodes=max([x[\"data\"].num_nodes for x in dataset])\n",
        "# print([x[\"data\"].num_nodes for x in dataset])\n",
        "if ([x[\"static\"].num_nodes for x in dataset if x[\"static\"].num_nodes]):\n",
        "  max_num_static_nodes=max([x[\"static\"].num_nodes for x in dataset])\n",
        "else:\n",
        "  max_num_static_nodes=0\n",
        "\n",
        "num_train_samples = int(0.7*len(dataset))\n",
        "random.shuffle(dataset)\n",
        "train_dataset = dataset[0:num_train_samples]\n",
        "test_dataset = dataset[num_train_samples:]\n",
        "\n",
        "print(f\"num train data: {len(train_dataset)}\\nnum test data: {len(test_dataset)}\\n\")\n",
        "print(f\"total num of nonstatic nodes: {sum([data['data'].num_nodes for data in dataset])}\")\n",
        "print(f\"total num of static nodes: {sum([data['static'].num_nodes for data in dataset])}\")\n",
        "\n",
        "tot_num_nodes=sum([data.num_nodes for data in dataset])\n",
        "tot_num_edges=sum([data.num_edges for data in dataset])\n",
        "\n",
        "print(f\"\\nTotal number of nodes: {tot_num_nodes}\")\n",
        "print(f\"Average number of nodes per Graph: {tot_num_nodes/len(dataset):.1f}\")\n",
        "print(f\"Total number of edges: {tot_num_edges}\")\n",
        "\n",
        "distrubution = [0 for i in range(NUM_EDGE_CLASSES)]\n",
        "for data in dataset:\n",
        "  for edge_types in data.collect(\"edge_attr\").values():\n",
        "    for egde_label in edge_types:\n",
        "      distrubution[egde_label] += 1\n",
        "\n",
        "print(f\"\"\"\\nDistrubution of edge classes in dataset:\n",
        "          Moving left to right:   {distrubution[0]},    {distrubution[0]/tot_num_edges*100:.2f}%\n",
        "          Moving right to left:   {distrubution[1]},    {distrubution[1]/tot_num_edges*100:.2f}%\n",
        "          Moving forward:         {distrubution[2]},   {distrubution[2]/tot_num_edges*100:.2f}%\n",
        "          Moving backward:        {distrubution[3]},   {distrubution[3]/tot_num_edges*100:.2f}%\n",
        "          No change:              {distrubution[4]},  {distrubution[4]/tot_num_edges*100:.2f}%\n",
        "      \"\"\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Dataset Metadata: \", end=\"\")\n",
        "dataset[0].metadata()"
      ],
      "metadata": {
        "id": "yBaEgTqEBZjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15fd7ef-b464-4f9a-c909-2a6d7932d790"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num train data: 593\n",
            "num test data: 255\n",
            "\n",
            "total num of nonstatic nodes: 4688\n",
            "total num of static nodes: 384\n",
            "\n",
            "Total number of nodes: 5072\n",
            "Average number of nodes per Graph: 6.0\n",
            "Total number of edges: 12040\n",
            "\n",
            "Distrubution of edge classes in dataset:\n",
            "          Moving left to right:   40,    0.33%\n",
            "          Moving right to left:   40,    0.33%\n",
            "          Moving forward:         384,   3.19%\n",
            "          Moving backward:        384,   3.19%\n",
            "          No change:              11192,  92.96%\n",
            "      \n",
            "Dataset Metadata: "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['data', 'static'],\n",
              " [('data', 'edge', 'data'),\n",
              "  ('data', 'edge', 'static'),\n",
              "  ('static', 'edge', 'data'),\n",
              "  ('static', 'edge', 'static')])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "uxkDlFTJAaR7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, NUM_EDGE_CLASSES)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return (x)\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_user[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_user * edge_feat_movie)#.sum(dim=-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "\n",
        "        self.data_lin = torch.nn.Linear(NUM_NODE_FEATURES, hidden_channels)\n",
        "        self.static_lin = torch.nn.Linear(NUM_NODE_FEATURES, hidden_channels)\n",
        "\n",
        "        self.data_emb = torch.nn.Embedding(max_num_data_nodes+max_num_static_nodes, hidden_channels)\n",
        "        self.static_emb = torch.nn.Embedding(max_num_static_nodes+max_num_data_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        # self.gnn = to_hetero(self.gnn, metadata = (['data'], [('data',\"edge\",'data')]) )\n",
        "        self.gnn = to_hetero(self.gnn, metadata =dataset[0].metadata())\n",
        "\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"data\":   self.data_lin(data[\"data\"].x.float()) + self.data_emb(data[\"data\"].node_id),\n",
        "          \"static\":   self.static_lin(data[\"static\"].x.float()) + self.static_emb(data[\"static\"].node_id)\n",
        "        }\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"data\"],\n",
        "            data['data', 'edge', 'data'].edge_index\n",
        "        )\n",
        "        return pred\n"
      ],
      "metadata": {
        "id": "_QItaZ3KN99R"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNDERSAMPLE_TRAIN_EDGES = True\n",
        "TRAIN_NOCHANGE_RATIO = 0.98 #ratio to undersample the 'No Change' label by\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "\n",
        "print(model)\n",
        "\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "nc=0\n",
        "nnc=0\n",
        "#changed activation function of the last layer of gnn from nothing to sigmoid to make it fit into 0-1\n",
        "for epoch in range(1, 100):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "        # pred = torch.argmax( model(sampled_data), dim=-1)\n",
        "        ground_truth = sampled_data['data', 'edge', 'data'].edge_attr.reshape(-1)\n",
        "\n",
        "        #add training mask to under sample the nochange (=4) label\n",
        "        if(UNDERSAMPLE_TRAIN_EDGES):\n",
        "          mask=[True if data!=4 or random.random()>TRAIN_NOCHANGE_RATIO else False for data in ground_truth]\n",
        "          pred=pred[mask]\n",
        "          ground_truth=ground_truth[mask]\n",
        "\n",
        "        if(ground_truth.numel()==0):continue\n",
        "\n",
        "\n",
        "        nc+=sum(ground_truth[ground_truth == 4] == 4)\n",
        "        nnc+=len(ground_truth)\n",
        "\n",
        "        loss = F.cross_entropy(pred, ground_truth)\n",
        "        # loss = ((torch.argmax(pred, dim=-1) - ground_truth) ** 2).mean()\n",
        "\n",
        "        # print(f\"pred= {pred}\")\n",
        "        # print(f\"ground truth = {ground_truth}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "\n",
        "        if total_examples>1:break\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")\n",
        "\n",
        "if(UNDERSAMPLE_TRAIN_EDGES):\n",
        "  print()\n",
        "  print(f\"Num of 'No Change' edges: {nc}\")\n",
        "  print(f\"Ratio of 'No Change' edges to total: {nc/nnc:.2f}\")"
      ],
      "metadata": {
        "id": "yVC2llbmAaUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12530d3-ad1e-4d24-bdae-76d686e12263"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (data_lin): Linear(in_features=3, out_features=64, bias=True)\n",
            "  (static_lin): Linear(in_features=3, out_features=64, bias=True)\n",
            "  (data_emb): Embedding(23, 64)\n",
            "  (static_emb): Embedding(23, 64)\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 64, aggr=mean)\n",
            "      (data__edge__static): SAGEConv(64, 64, aggr=mean)\n",
            "      (static__edge__data): SAGEConv(64, 64, aggr=mean)\n",
            "      (static__edge__static): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 5, aggr=mean)\n",
            "      (data__edge__static): SAGEConv(64, 5, aggr=mean)\n",
            "      (static__edge__data): SAGEConv(64, 5, aggr=mean)\n",
            "      (static__edge__static): SAGEConv(64, 5, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Classifier()\n",
            ")\n",
            "Device: 'cpu'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 1.3610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:17, 32.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 3.5331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:16, 35.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 8.6516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:18, 32.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 4.1630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Loss: 2.6295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 006, Loss: 0.5750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 007, Loss: 0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 008, Loss: 3.6355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 009, Loss: 3.5259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:25, 23.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 7.5207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:10, 56.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 011, Loss: 1.3996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 4/593 [00:00<00:09, 62.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 012, Loss: 1.2881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 013, Loss: 1.9469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 014, Loss: 1.8215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 015, Loss: 3.8530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 016, Loss: 1.6395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:20, 29.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 017, Loss: 2.9008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 018, Loss: 0.5696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 019, Loss: 2.2446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:25, 23.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 020, Loss: 4.6920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:19, 29.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 021, Loss: 3.7659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 022, Loss: 1.6005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 023, Loss: 3.1486"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:13, 42.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 024, Loss: 2.6320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:11, 50.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 025, Loss: 2.1090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/593 [00:00<00:10, 55.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 026, Loss: 1.7935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 027, Loss: 1.4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 028, Loss: 1.2651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 9/593 [00:00<00:08, 67.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 029, Loss: 1.8310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:13, 43.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 030, Loss: 1.3222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 031, Loss: 2.4386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:15, 38.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 032, Loss: 1.5219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:14, 41.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 033, Loss: 0.9625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 034, Loss: 6.6674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:11, 51.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 035, Loss: 1.0871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:19, 30.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 036, Loss: 1.4803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:13, 42.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 037, Loss: 1.0692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 5/593 [00:00<00:10, 56.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 038, Loss: 1.8702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:11, 51.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 039, Loss: 1.4346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 040, Loss: 3.7423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 041, Loss: 2.4109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:11, 50.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 042, Loss: 0.9758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 043, Loss: 4.2957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:12, 48.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 044, Loss: 1.2446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 045, Loss: 1.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 4/593 [00:00<00:07, 77.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 046, Loss: 2.9026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:08, 69.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 047, Loss: 2.5275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 5/593 [00:00<00:05, 105.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 048, Loss: 1.6027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 049, Loss: 3.8313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 050, Loss: 1.5456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 051, Loss: 1.1612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:15, 37.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 052, Loss: 1.4593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 053, Loss: 1.1637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:06, 88.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 054, Loss: 2.1401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:08, 67.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 055, Loss: 1.2488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 056, Loss: 1.4414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 057, Loss: 1.5064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 058, Loss: 2.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:09, 62.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 059, Loss: 1.2103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 4/593 [00:00<00:07, 82.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 060, Loss: 1.4066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 061, Loss: 1.2176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:14, 42.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 062, Loss: 1.2214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:08, 67.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 063, Loss: 1.4507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 064, Loss: 2.1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:19, 30.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 065, Loss: 1.0870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:16, 36.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 066, Loss: 1.1293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 067, Loss: 4.6758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:06, 94.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 068, Loss: 1.3758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:11, 53.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 069, Loss: 1.4837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:13, 42.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 070, Loss: 1.0303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 9/593 [00:00<00:05, 116.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 071, Loss: 1.2342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:15, 38.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 072, Loss: 1.0861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:14, 42.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 073, Loss: 1.5230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:07, 82.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 074, Loss: 1.1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 075, Loss: 1.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 076, Loss: 2.0839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 7/593 [00:00<00:05, 98.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 077, Loss: 1.0179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:07, 74.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 078, Loss: 1.1647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:07, 83.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 079, Loss: 1.9706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:15, 38.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 080, Loss: 0.0226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:16, 36.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 081, Loss: 2.5153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 082, Loss: 0.9944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 083, Loss: 2.8663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 084, Loss: 1.7797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:08, 66.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 085, Loss: 1.2037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:12, 48.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 086, Loss: 1.0293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 087, Loss: 1.3181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/593 [00:00<00:07, 74.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 088, Loss: 1.1155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:17, 33.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 089, Loss: 1.0200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:07, 74.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 090, Loss: 1.0590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:23, 25.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 091, Loss: 1.4037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:09, 61.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 092, Loss: 2.7976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:21, 27.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 093, Loss: 1.3316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:14, 40.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 094, Loss: 1.1766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/593 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 095, Loss: 1.5648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 4/593 [00:00<00:06, 97.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 096, Loss: 1.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:17, 33.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 097, Loss: 1.2883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 3/593 [00:00<00:07, 79.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 098, Loss: 3.8993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/593 [00:00<00:14, 40.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 099, Loss: 1.0659\n",
            "\n",
            "Num of 'No Change' edges: 55\n",
            "Ratio of 'No Change' edges to total: 0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNDERSAMPLE_TEST_EDGES = True\n",
        "TEST_NOCHANGE_RATIO = 1 #ratio to undersample the 'No Change' label by\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "right_graph=0\n",
        "right_edge=0\n",
        "c=0\n",
        "nc=0\n",
        "for sampled_data in (test_dataset):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        pred=torch.argmax(model(sampled_data), dim=-1)\n",
        "        ground_truth = sampled_data['data', 'edge', 'data'].edge_attr.reshape(-1)\n",
        "\n",
        "        if(UNDERSAMPLE_TEST_EDGES):\n",
        "          mask=[True if data!=4 or random.random() > TEST_NOCHANGE_RATIO else False for data in ground_truth]\n",
        "          pred=pred[mask]\n",
        "          ground_truth=ground_truth[mask]\n",
        "\n",
        "          nc+=sum(ground_truth[ground_truth == 4] == 4)\n",
        "          print(pred)\n",
        "        if(ground_truth.numel()==0):continue\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(ground_truth)\n",
        "        if(list(pred)==list(ground_truth)): right_graph += 1\n",
        "        for i in range(len(pred)):\n",
        "          if pred[i]==ground_truth[i]:\n",
        "            right_edge+=1\n",
        "          c+=1\n",
        "\n",
        "if(UNDERSAMPLE_TEST_EDGES):\n",
        "  print(f\"Num of 'No Change' edges: {nc}\")\n",
        "  print(f\"Ratio of 'No Change' edges to total: {nc/c:.2f}\")\n",
        "  print()\n",
        "\n",
        "print(f\"Top-1 Edge Acc:{right_edge/c*100:.2f}%, number of right guess: {right_edge}, from {c} number of edges\")\n",
        "print(f\"Complate Graph Acc:{right_graph/len(test_dataset)*100:.2f}%, number of right guess: {right_graph}, from {len(test_dataset)} number of graphs\")\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "pred=[int(p) for p in pred]\n",
        "ground_truth=[int(p) for p in ground_truth]"
      ],
      "metadata": {
        "id": "kzkLoQh6cGFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8207b92-f6fa-407a-c4d5-a524c4b5e3e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 2, 2])\n",
            "tensor([3, 3])\n",
            "tensor([3, 3])\n",
            "tensor([2, 2])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 2, 2, 4, 2, 2, 2, 2, 2, 2])\n",
            "tensor([3, 3])\n",
            "tensor([2, 2, 2, 2])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([2, 2])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([2, 4, 2, 2, 4, 2])\n",
            "tensor([1, 1])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([3, 4, 3, 3, 4, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([2, 2, 2, 4, 2, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
            "tensor([4, 4, 4, 4, 4, 2, 2, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([4, 4])\n",
            "tensor([1, 1])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([4, 4])\n",
            "tensor([4, 4, 2, 2])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([4, 4])\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 2, 4, 2, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 2, 2, 4, 2, 2, 2, 2, 2, 2])\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 4, 3, 3, 4, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4])\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([1, 1])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([4, 4, 4, 4, 4, 2, 2, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([1, 1])\n",
            "tensor([2, 2, 2, 2, 2, 2, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([2, 2])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([4, 4, 4, 4])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([3, 3])\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "Num of 'No Change' edges: 0\n",
            "Ratio of 'No Change' edges to total: 0.00\n",
            "\n",
            "Top-1 Edge Acc:22.77%, number of right guess: 51, from 224 number of edges\n",
            "Complate Graph Acc:0.00%, number of right guess: 0, from 255 number of graphs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(ground_truth, pred, labels=[0,1,2,3,4], normalize=None)\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Greens');  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "ax.set_xlabel('Predicted labels');\n",
        "ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "x_labels=['LTR', 'RTL', 'MF', 'MB', 'NC']\n",
        "y_labels=x_labels\n",
        "ax.xaxis.set_ticklabels(x_labels); ax.yaxis.set_ticklabels(y_labels);"
      ],
      "metadata": {
        "id": "ajLewHP05io0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "e490dcb6-1415-4344-aabf-e0fc4a80b39b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum([1 if p==4 else 0 for p in ground_truth])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r04LJNWXKKBc",
        "outputId": "abc0388e-557a-4cb2-ec1d-cc56663b4f46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "507"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#not used!!!\n",
        "raise ValueError"
      ],
      "metadata": {
        "id": "zMR4BPO8G2JJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "e31f38a3-66de-46a7-849d-5990dcd4ebc7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2f116213d9b2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#not used!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dataset=[]\n",
        "graph_list=torch.load(PATH + \"/IA_graph_dataset\")\n",
        "for g in graph_list:\n",
        "  remapped_g = nx.convert_node_labels_to_integers(g) #remaps the ndes (and edges) to format like 0,1,2...N\n",
        "  d = from_networkx(remapped_g, )\n",
        "  #hd = d.to_heterogeneous(node_type_names=([\"data\"]), edge_type_names=[(\"data\",\"edge\",\"data\")])\n",
        "  # d = from_networkx(g)\n",
        "  # nx.get_node_attributes(graph_list[0], \"xy\")\n",
        "  nodes = remapped_g.nodes()\n",
        "\n",
        "  #\"resets\" the node id and removes isolated nodes\n",
        "  edge_index = d.edge_index\n",
        "  nodes = torch.unique(edge_index) #removes isolated nodes\n",
        "  edge_label = d.label\n",
        "\n",
        "  # node_xy = [int(g.nodes[node][\"xy\"][0]) for node in g.nodes]\n",
        "  # node_x, node_y = torch.split(d.xy, split_size_or_sections=1, dim=1)\n",
        "  node_x = d.xy[:, 0]\n",
        "  node_y = d.xy[:, 1]\n",
        "\n",
        "\n",
        "  data = HeteroData()\n",
        "  edge_label = torch.FloatTensor( [float(i) for i in list(edge_label)])\n",
        "  data[\"data\"].node_id = torch.IntTensor( [int(i) for i in list(nodes)])\n",
        "\n",
        "  data[\"data\"].num_nodes = d.num_nodes\n",
        "\n",
        "  node_features=torch.stack([node_x, node_y]).t()\n",
        "\n",
        "  data[\"data\"].x = node_features\n",
        "  data['data', 'edge', 'data'].edge_index = edge_index\n",
        "\n",
        "  #create it as size edge_label*num_classes\n",
        "  # use torch_geometric.utils.one_hot() instead does the same thing\n",
        "  def change_edge_label_dim(edge_label):\n",
        "    zero_list = lambda n=0: [0. for i in range(n)]\n",
        "    el=[]\n",
        "    for label in edge_label:\n",
        "      temp=zero_list(NUM_EDGE_CLASSES)\n",
        "      temp[int(label)]=1.0\n",
        "      el.append(temp)\n",
        "    return torch.FloatTensor(el)\n",
        "\n",
        "  data['data', 'edge', 'data'].edge_label = change_edge_label_dim(edge_label)\n",
        "  # data['data', 'edge', 'data'].edge_label = edge_label\n",
        "\n",
        "  dataset.append(data)\n",
        "\n",
        "  # Save node indices:\n",
        "  '''\n",
        "  data.node_id = Tensor(list(B.nodes()))\n",
        "\n",
        "  # Add the node features and edge indices:\n",
        "  data.x = np.ones(B.number_of_nodes())\n",
        "\n",
        "  data.edge_index = edge_index\n",
        "  data.edge_label = edge_label\n",
        "  data.number_of_nodes =  num_nodes\n",
        "\n",
        "  '''\n",
        "  # Add the node features and edge indices:\n",
        "  #data[\"data\"].x = np.ones(B.number_of_nodes())\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "#data = T.ToUndirected()(data)"
      ],
      "metadata": {
        "id": "YipHUM8gGeIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate fake/debugging dataset\n",
        "# sample_data=dataset[0]\n",
        "# dataset=[]\n",
        "# for i in range(1000):\n",
        "#   dataset.append(sample_data)"
      ],
      "metadata": {
        "id": "pzSm8eodBgn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load graph object from file\n",
        "#d = pickle.load(open('sampled_data.pickle', 'rb'))"
      ],
      "metadata": {
        "id": "j606YjzWCJGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try 2\n",
        "from torch_geometric.nn import GraphConv\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(-1, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 9)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        x, edge_index, batch = data[\"data\"].node_id, data[(\"data\", \"edge\", \"data\")].edge_index, data[\"data\"].batch\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        #x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = GNN(hidden_channels=64)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "3RvZ1gJnOoGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xb0SrTACUTyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset"
      ],
      "metadata": {
        "id": "k3RJTT7GAZHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index_dict\n"
      ],
      "metadata": {
        "id": "QgV7JCnL6ulh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=data.metadata()\n",
        "names = metadata[0] + [rel for _, rel, _ in metadata[1]]\n",
        "for name in names:\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "WjFZAht0r5N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " data[\"edge\"].edge_index"
      ],
      "metadata": {
        "id": "GdPJxmmsWeNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "Ak9niIxODTeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7l60br3AaXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxHZP4fQAaZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBTK_1BfAabk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSVmVsohAad4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "#IG[data.edge_index[0][i].item()][2]\n",
        "print(IG[data.edge_index[0][i].item()+1][data.edge_index[1][i].item()+1])"
      ],
      "metadata": {
        "id": "ojqOb25y7o8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=from_networkx(IG)\n",
        "print(data.edge_index)\n",
        "edge_attr=[]\n",
        "for i in range(len(data.edge_index[0])):\n",
        "  print([data.edge_index[0][i]+1][0].item())\n",
        "  t=(IG[data.edge_index[0][i].item()][data.edge_index[1][i].item()])\n",
        "  print(t)\n",
        "  edge_attr.append=t\n",
        "edge_attr\n",
        "#edge_attr= [IG[] for i in data.edge_index]\n",
        "#print(edge_attr)\n",
        "\n",
        "\n",
        "'''\n",
        "edge_attr[i] corresponds to the edge\n",
        "between edge_index[0][i] and edge_index[1][i].\n",
        "'''\n"
      ],
      "metadata": {
        "id": "WoDgpsOAsF3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index=[for i in IG.edges()]\n"
      ],
      "metadata": {
        "id": "WzhVuFifq2Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install dgl\n",
        "\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qBpBTGxGdmKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "q1dvS2D_gIVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "nx.write_edgelist(B,PATH+\"/IA_graph1.csv\",data=[\"label\"], delimiter =\",\" )\n"
      ],
      "metadata": {
        "id": "-YsX82bEJNWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)\n",
        "d=from_networkx(B)\n",
        "edge_index = d.edge_index\n",
        "edge_label = d.label\n",
        "num_nodes = d.num_nodes\n"
      ],
      "metadata": {
        "id": "zSCIwjO7JO1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph=pd.read_csv(PATH + \"/IA_graph1.csv\", header=None, names=[\"src\",'dst','label'])\n",
        "graph"
      ],
      "metadata": {
        "id": "Jn_rx9oQJuEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = np.random.randint(0, 100, 500)\n",
        "dst = np.random.randint(0, 100, 500)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "edge_pred_graph.edata['feature'] = torch.randn(1000, 10)\n",
        "edge_pred_graph.edata['label'] = torch.randn(1000)\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(1000, dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SJpTKrcxq4Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph"
      ],
      "metadata": {
        "id": "dn9qon6OQCQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)"
      ],
      "metadata": {
        "id": "G_9ix10yRyxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph.num_edges()"
      ],
      "metadata": {
        "id": "lOZGUa0oU-cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "edge_pred_graph=dgl.from_networkx(B, edge_attrs=[\"label\"])\n",
        "#edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)\n",
        "edge_pred_graph.edata['train_mask']\n"
      ],
      "metadata": {
        "id": "OA_iqIKSQCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(graph))\n",
        "src = graph.src\n",
        "dst = graph.dst\n",
        "num_edges=len(graph)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "#edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "# edge_pred_graph.edata['feature'] = graph.label\n",
        "edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SO5-wmb-Itpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTP9oylYHDpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkCrIptJdbJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNrLbiorddYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWyJQyIzdiYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contruct a two-layer GNN model\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # inputs are features of nodes\n",
        "        print(graph)\n",
        "        print(inputs)\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "import dgl.function as fn\n",
        "class DotProductPredictor(nn.Module):\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, in_features, out_classes):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(in_features * 2, out_classes)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        h_u = edges.src['h']\n",
        "        h_v = edges.dst['h']\n",
        "        score = self.W(torch.cat([h_u, h_v], 1))\n",
        "        return {'score': score}\n",
        "\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(self.apply_edges)\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super().__init__()\n",
        "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
        "        self.pred = DotProductPredictor()\n",
        "    def forward(self, g, x):\n",
        "        h = self.sage(g, x)\n",
        "        return self.pred(g, h)\n",
        "\n",
        "from torch import Tensor\n",
        "# node_features = edge_pred_graph.ndata['feature']\n",
        "edge_label = edge_pred_graph.edata['label']\n",
        "train_mask = edge_pred_graph.edata['train_mask']\n",
        "model = Model(1, 20, 10)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "pred = model(edge_pred_graph, Tensor())\n",
        "loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "opt.zero_grad()\n",
        "loss.backward()\n",
        "opt.step()\n",
        "print(loss.item())\n",
        "\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     pred = model(edge_pred_graph, Tensor())\n",
        "#     loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "#     opt.zero_grad()\n",
        "#     loss.backward()\n",
        "#     opt.step()\n",
        "#     print(loss.item())"
      ],
      "metadata": {
        "id": "lX394xGDdkSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpqQ_mRqdFOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class EdgePredictor(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EdgePredictor, self).__init__(aggr='max')  # Use max pooling for message aggregation\n",
        "\n",
        "        self.node_idx = torch.arange(in_channels, dtype=torch.long)\n",
        "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x: Node features\n",
        "        # edge_index: Graph connectivity\n",
        "\n",
        "        # Add self-loops for the message passing\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Calculate the normalized degree for each node\n",
        "        deg = degree(edge_index[0], x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        # Calculate the normalized adjacency matrix\n",
        "        norm = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
        "        edge_index_norm = Tensor((2,200))\n",
        "        print((edge_index / norm).size())\n",
        "        print((edge_index).size())\n",
        "        edge_index_norm = (edge_index / norm).int\n",
        "        return self.propagate(edge_index=edge_index_norm, size=(x.size(0), x.size(0)), x=x)\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        aggr_out = torch.cat([aggr_out, x[self.node_idx]], dim=-1)\n",
        "        aggr_out = F.relu(self.lin(aggr_out))\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Initialize the model\n",
        "model = GNNEdgeClassifier(in_channels=1, hidden_channels=32, out_channels=11)  # 11 classes (0 to 10)\n",
        "\n",
        "# Example data (replace with your own data)\n",
        "x = torch.randn(100, 1)  # Node features (not used in this example)\n",
        "edge_index = torch.randint(0, 100, (2, 200), dtype=torch.long)  # Random edge connectivity\n",
        "edge_labels = torch.randint(0, 11, (200,), dtype=torch.long)  # Random edge labels (0 to 10)\n",
        "\n",
        "# Forward pass\n",
        "predictions = model(x, edge_index)\n",
        "\n",
        "# Calculate loss (replace with your own loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(predictions, edge_labels)\n"
      ],
      "metadata": {
        "id": "7QEW1FPzeS1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPioOvKCZp37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}