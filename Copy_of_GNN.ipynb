{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND4pXMSjU+hgrxSC7f4vtc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erkiperkki/IL2232/blob/main/Copy_of_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import from_networkx\n",
        "import networkx as nx\n",
        "# https://colab.research.google.com/github/Erkiperkki/IL2232/blob/main/GNN.ipynb\n",
        "\n",
        "'''\n",
        "Todoo:\n",
        "fix results to vector\n",
        "Compare with mlp\n",
        "add features from nodes\n",
        "'''"
      ],
      "metadata": {
        "id": "TFudoUnorwrj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "04cafeff-7f18-445a-cd74-f75222cddd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTodoo:\\nfix results to vector\\nCompare with mlp\\nadd features from nodes\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSV89xyoK_wM",
        "outputId": "d9607e4c-d6d1-4635-8455-73e2b2371ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH=\"/content/drive/MyDrive/Embedded Systems Design Project\"\n",
        "NUM_EDGE_CLASSES = 5\n",
        "#/content/drive/MyDrive/Embedded Systems Design Project/output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "dataset=[]\n",
        "graph_list=torch.load(PATH + \"/IA_graph_dataset\")\n",
        "for g in graph_list:\n",
        "  d = from_networkx(g)\n",
        "  nx.get_node_attributes(graph_list[0], \"xy\")\n",
        "  nodes = g.nodes()\n",
        "  node_xy = [int(g.nodes[node][\"xy\"][0]) for node in g.nodes]\n",
        "  edge_index = d.edge_index\n",
        "  edge_label = d.label\n",
        "  num_nodes = d.num_nodes\n",
        "\n",
        "  data = HeteroData()\n",
        "  edge_label = torch.FloatTensor( [float(i) for i in list(edge_label)])\n",
        "  data[\"data\"].node_id = torch.IntTensor( [int(i) for i in list(nodes)])\n",
        "  data[\"data\"].x = torch.IntTensor( node_xy)\n",
        "\n",
        "  data['data', 'edge', 'data'].edge_index = edge_index\n",
        "\n",
        "  #create it as size edge_label*num_classes\n",
        "  def change_edge_label_dim(edge_label):\n",
        "    zero_list = lambda n=0: [0. for i in range(n)]\n",
        "    el=[]\n",
        "    for label in edge_label:\n",
        "      temp=zero_list(NUM_EDGE_CLASSES)\n",
        "      temp[int(label)]=1.0\n",
        "      el.append(temp)\n",
        "    return torch.FloatTensor(el)\n",
        "\n",
        "  data['data', 'edge', 'data'].edge_label = change_edge_label_dim(edge_label)\n",
        "  # data['data', 'edge', 'data'].edge_label = edge_label\n",
        "\n",
        "  dataset.append(data)\n",
        "\n",
        "  # Save node indices:\n",
        "  '''\n",
        "  data.node_id = Tensor(list(B.nodes()))\n",
        "\n",
        "  # Add the node features and edge indices:\n",
        "  data.x = np.ones(B.number_of_nodes())\n",
        "\n",
        "  data.edge_index = edge_index\n",
        "  data.edge_label = edge_label\n",
        "  data.number_of_nodes =  num_nodes\n",
        "\n",
        "  '''\n",
        "  # Add the node features and edge indices:\n",
        "  #data[\"data\"].x = np.ones(B.number_of_nodes())\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "#data = T.ToUndirected()(data)"
      ],
      "metadata": {
        "id": "YipHUM8gGeIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate fake/debugging dataset\n",
        "# sample_data=dataset[0]\n",
        "# dataset=[]\n",
        "# for i in range(1000):\n",
        "#   dataset.append(sample_data)"
      ],
      "metadata": {
        "id": "pzSm8eodBgn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_train_samples = int(0.7*len(dataset))\n",
        "\n",
        "train_dataset = dataset[0:num_train_samples]\n",
        "test_dataset = dataset[num_train_samples:]"
      ],
      "metadata": {
        "id": "yBaEgTqEBZjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load graph object from file\n",
        "#d = pickle.load(open('sampled_data.pickle', 'rb'))"
      ],
      "metadata": {
        "id": "j606YjzWCJGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "uxkDlFTJAaR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_num_nodes=sum([data.num_nodes for data in dataset])"
      ],
      "metadata": {
        "id": "CUGKtBB-Dz4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, NUM_EDGE_CLASSES)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.sigmoid(x)\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_user[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "\n",
        "        return (edge_feat_user * edge_feat_movie)#.sum(dim=-1)\n",
        "\n",
        "        #ones=torch.ones(edge_feat_user.size(), dtype=torch.long)\n",
        "        #return  (edge_feat_user * ones).sum(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "\n",
        "        self.movie_lin = torch.nn.Linear(1, hidden_channels)\n",
        "\n",
        "        self.data_emb = torch.nn.Embedding(tot_num_nodes, hidden_channels)\n",
        "        #self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata = (['data'], [('data',\"edge\",'data')]) )\n",
        "\n",
        "        #([\"node_id\"],[\"edge_index\"])\n",
        "\n",
        "        #look here need to change metedata to all possible types\n",
        "\n",
        "        '''\n",
        "(['user', 'movie'],\n",
        " [('user', 'rates', 'movie'), ('movie', 'rev_rates', 'user')])\n",
        "\n",
        "which node representations are learned for each node type in\n",
        "metadata[0], and messages are exchanged between each edge type in\n",
        "metadata[1], as denoted in the \"Modeling Relational Data with Graph Convolutional Networks\" <https://arxiv.org/abs/1703.06103>_ paper:\n",
        "\n",
        "where x_dict and edge_index_dict denote dictionaries that\n",
        "hold node features and edge connectivity information for each node type and\n",
        "edge type, respectively.\n",
        "\n",
        "        '''\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "\n",
        "\n",
        "        x_dict = {\n",
        "          \"data\":   self.data_emb(data[\"data\"].node_id),\n",
        "          #\"data\":   self.data_emb(data[\"data\"].x) + self.data_emb(data[\"data\"].node_id),\n",
        "          #\"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
        "        }\n",
        "        #print(x_dict)\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"data\"],\n",
        "            data['data', 'edge', 'data'].edge_index\n",
        "            #data['data', 'edge', 'data'].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "#model = GNN(hidden_channels=64)\n",
        "\n",
        "print(model)\n",
        "\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "#changed activation function of the last layer of gnn from nothing to sigmoid to make it fit into 0-1\n",
        "for epoch in range(1, 5):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "        # pred = torch.argmax( model(sampled_data), dim=-1, )\n",
        "\n",
        "        ground_truth = sampled_data['data', 'edge', 'data'].edge_label\n",
        "\n",
        "        # loss = F.binary_cross_entropy_with_logits(model(sampled_data), ground_truth)\n",
        "\n",
        "        loss = ((pred - ground_truth) ** 2).mean()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "yVC2llbmAaUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f55e4a5-cccb-42ed-8b55-9a421d8fdb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (movie_lin): Linear(in_features=1, out_features=64, bias=True)\n",
            "  (data_emb): Embedding(56, 64)\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 5, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Classifier()\n",
            ")\n",
            "Device: 'cpu'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 132.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.1627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 95.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.0914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 94.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.0566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 84.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.0475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import roc_auc_score\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "right_graph=0\n",
        "right_edge=0\n",
        "c=0\n",
        "for sampled_data in (test_dataset):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        pred=torch.argmax(model(sampled_data), dim=-1)\n",
        "        ground_truth=torch.argmax(model(sampled_data), dim=-1)\n",
        "\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(ground_truth)\n",
        "        if(list(pred)==list(ground_truth)): right_graph += 1\n",
        "        for i in range(len(pred)-1):\n",
        "          if pred[i]==ground_truth[i]:\n",
        "            right_edge+=1\n",
        "          c+=1\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Top-1 Edge Acc:{right_edge/c*100}%, number of right guess: {right_edge}, from {c} number of edges\")\n",
        "print(f\"Complate Graph Acc:{right_graph/len(test_dataset)*100}%, number of right guess: {right_graph}, from {len(test_dataset)} number of graphs\")\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "pred=[int(p) for p in pred]\n",
        "ground_truth=[int(p) for p in ground_truth]"
      ],
      "metadata": {
        "id": "kzkLoQh6cGFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "67b8ed75-2544-49ba-fc59-e8c034103075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-300-76f6692eedfa>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msampled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mground_truth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-299-e37ce31edefc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         x_dict = {\n\u001b[0;32m---> 74\u001b[0;31m           \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m           \u001b[0;31m#\"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         }\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(ground_truth, pred, labels=[0,1,2,3,4])\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Greens');  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "ax.set_xlabel('Predicted labels');\n",
        "ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "x_labels=['LTR', 'RTL', 'MF', 'MB', 'NC']\n",
        "y_labels=x_labels\n",
        "ax.xaxis.set_ticklabels(x_labels); ax.yaxis.set_ticklabels(y_labels);\n",
        "#auc = roc_auc_score(ground_truth, pred, multi_class=\"ovo\")\n",
        "# print()\n",
        "# print(f\"Validation AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "ajLewHP05io0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "81be6491-8a87-4734-f7a0-1da0caa6b8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#not used!!!\n",
        "raise ValueError"
      ],
      "metadata": {
        "id": "zMR4BPO8G2JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try 2\n",
        "from torch_geometric.nn import GraphConv\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(-1, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 9)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        x, edge_index, batch = data[\"data\"].node_id, data[(\"data\", \"edge\", \"data\")].edge_index, data[\"data\"].batch\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        #x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = GNN(hidden_channels=64)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "3RvZ1gJnOoGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xb0SrTACUTyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset"
      ],
      "metadata": {
        "id": "k3RJTT7GAZHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index_dict\n"
      ],
      "metadata": {
        "id": "QgV7JCnL6ulh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=data.metadata()\n",
        "names = metadata[0] + [rel for _, rel, _ in metadata[1]]\n",
        "for name in names:\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "WjFZAht0r5N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " data[\"edge\"].edge_index"
      ],
      "metadata": {
        "id": "GdPJxmmsWeNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "Ak9niIxODTeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7l60br3AaXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxHZP4fQAaZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBTK_1BfAabk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSVmVsohAad4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "#IG[data.edge_index[0][i].item()][2]\n",
        "print(IG[data.edge_index[0][i].item()+1][data.edge_index[1][i].item()+1])"
      ],
      "metadata": {
        "id": "ojqOb25y7o8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=from_networkx(IG)\n",
        "print(data.edge_index)\n",
        "edge_attr=[]\n",
        "for i in range(len(data.edge_index[0])):\n",
        "  print([data.edge_index[0][i]+1][0].item())\n",
        "  t=(IG[data.edge_index[0][i].item()][data.edge_index[1][i].item()])\n",
        "  print(t)\n",
        "  edge_attr.append=t\n",
        "edge_attr\n",
        "#edge_attr= [IG[] for i in data.edge_index]\n",
        "#print(edge_attr)\n",
        "\n",
        "\n",
        "'''\n",
        "edge_attr[i] corresponds to the edge\n",
        "between edge_index[0][i] and edge_index[1][i].\n",
        "'''\n"
      ],
      "metadata": {
        "id": "WoDgpsOAsF3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index=[for i in IG.edges()]\n"
      ],
      "metadata": {
        "id": "WzhVuFifq2Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install dgl\n",
        "\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qBpBTGxGdmKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "q1dvS2D_gIVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "nx.write_edgelist(B,PATH+\"/IA_graph1.csv\",data=[\"label\"], delimiter =\",\" )\n"
      ],
      "metadata": {
        "id": "-YsX82bEJNWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)\n",
        "d=from_networkx(B)\n",
        "edge_index = d.edge_index\n",
        "edge_label = d.label\n",
        "num_nodes = d.num_nodes\n"
      ],
      "metadata": {
        "id": "zSCIwjO7JO1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph=pd.read_csv(PATH + \"/IA_graph1.csv\", header=None, names=[\"src\",'dst','label'])\n",
        "graph"
      ],
      "metadata": {
        "id": "Jn_rx9oQJuEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = np.random.randint(0, 100, 500)\n",
        "dst = np.random.randint(0, 100, 500)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "edge_pred_graph.edata['feature'] = torch.randn(1000, 10)\n",
        "edge_pred_graph.edata['label'] = torch.randn(1000)\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(1000, dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SJpTKrcxq4Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph"
      ],
      "metadata": {
        "id": "dn9qon6OQCQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)"
      ],
      "metadata": {
        "id": "G_9ix10yRyxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph.num_edges()"
      ],
      "metadata": {
        "id": "lOZGUa0oU-cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "edge_pred_graph=dgl.from_networkx(B, edge_attrs=[\"label\"])\n",
        "#edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)\n",
        "edge_pred_graph.edata['train_mask']\n"
      ],
      "metadata": {
        "id": "OA_iqIKSQCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(graph))\n",
        "src = graph.src\n",
        "dst = graph.dst\n",
        "num_edges=len(graph)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "#edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "# edge_pred_graph.edata['feature'] = graph.label\n",
        "edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SO5-wmb-Itpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTP9oylYHDpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkCrIptJdbJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNrLbiorddYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWyJQyIzdiYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contruct a two-layer GNN model\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # inputs are features of nodes\n",
        "        print(graph)\n",
        "        print(inputs)\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "import dgl.function as fn\n",
        "class DotProductPredictor(nn.Module):\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, in_features, out_classes):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(in_features * 2, out_classes)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        h_u = edges.src['h']\n",
        "        h_v = edges.dst['h']\n",
        "        score = self.W(torch.cat([h_u, h_v], 1))\n",
        "        return {'score': score}\n",
        "\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(self.apply_edges)\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super().__init__()\n",
        "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
        "        self.pred = DotProductPredictor()\n",
        "    def forward(self, g, x):\n",
        "        h = self.sage(g, x)\n",
        "        return self.pred(g, h)\n",
        "\n",
        "from torch import Tensor\n",
        "# node_features = edge_pred_graph.ndata['feature']\n",
        "edge_label = edge_pred_graph.edata['label']\n",
        "train_mask = edge_pred_graph.edata['train_mask']\n",
        "model = Model(1, 20, 10)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "pred = model(edge_pred_graph, Tensor())\n",
        "loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "opt.zero_grad()\n",
        "loss.backward()\n",
        "opt.step()\n",
        "print(loss.item())\n",
        "\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     pred = model(edge_pred_graph, Tensor())\n",
        "#     loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "#     opt.zero_grad()\n",
        "#     loss.backward()\n",
        "#     opt.step()\n",
        "#     print(loss.item())"
      ],
      "metadata": {
        "id": "lX394xGDdkSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpqQ_mRqdFOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class EdgePredictor(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EdgePredictor, self).__init__(aggr='max')  # Use max pooling for message aggregation\n",
        "\n",
        "        self.node_idx = torch.arange(in_channels, dtype=torch.long)\n",
        "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x: Node features\n",
        "        # edge_index: Graph connectivity\n",
        "\n",
        "        # Add self-loops for the message passing\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Calculate the normalized degree for each node\n",
        "        deg = degree(edge_index[0], x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        # Calculate the normalized adjacency matrix\n",
        "        norm = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
        "        edge_index_norm = Tensor((2,200))\n",
        "        print((edge_index / norm).size())\n",
        "        print((edge_index).size())\n",
        "        edge_index_norm = (edge_index / norm).int\n",
        "        return self.propagate(edge_index=edge_index_norm, size=(x.size(0), x.size(0)), x=x)\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        aggr_out = torch.cat([aggr_out, x[self.node_idx]], dim=-1)\n",
        "        aggr_out = F.relu(self.lin(aggr_out))\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Initialize the model\n",
        "model = GNNEdgeClassifier(in_channels=1, hidden_channels=32, out_channels=11)  # 11 classes (0 to 10)\n",
        "\n",
        "# Example data (replace with your own data)\n",
        "x = torch.randn(100, 1)  # Node features (not used in this example)\n",
        "edge_index = torch.randint(0, 100, (2, 200), dtype=torch.long)  # Random edge connectivity\n",
        "edge_labels = torch.randint(0, 11, (200,), dtype=torch.long)  # Random edge labels (0 to 10)\n",
        "\n",
        "# Forward pass\n",
        "predictions = model(x, edge_index)\n",
        "\n",
        "# Calculate loss (replace with your own loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(predictions, edge_labels)\n"
      ],
      "metadata": {
        "id": "7QEW1FPzeS1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPioOvKCZp37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}