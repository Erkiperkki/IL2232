{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ+thBTukWckuHVlWyPZvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erkiperkki/IL2232/blob/main/Copy_of_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import from_networkx\n",
        "import networkx as nx\n",
        "# https://colab.research.google.com/github/Erkiperkki/IL2232/blob/main/GNN.ipynb\n",
        "\n",
        "'''\n",
        "Todoo:\n",
        "fix results to vector\n",
        "Compare with mlp\n",
        "add features from nodes\n",
        "'''"
      ],
      "metadata": {
        "id": "TFudoUnorwrj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "e6f81c42-71ba-4b00-d275-944e3d41977f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTodoo:\\nfix results to vector\\nCompare with mlp\\nadd features from nodes \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSV89xyoK_wM",
        "outputId": "8eaadd97-df02-4bed-ee9c-88d5c00d54d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH=\"/content/drive/MyDrive/Embedded Systems Design Project\"\n",
        "\n",
        "#/content/drive/MyDrive/Embedded Systems Design Project/output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "dataset=[]\n",
        "graph_list=torch.load(PATH + \"/IA_graph.csv\")\n",
        "for g in graph_list:\n",
        "  d = from_networkx(g)\n",
        "\n",
        "  nodes = g.nodes()\n",
        "  edge_index = d.edge_index\n",
        "  edge_label = d.label\n",
        "  num_nodes = d.num_nodes\n",
        "\n",
        "  data = HeteroData()\n",
        "  edge_label = torch.FloatTensor( [float(i) for i in list(edge_label)])\n",
        "  data[\"data\"].node_id = torch.IntTensor( [int(i) for i in list(nodes)])\n",
        "\n",
        "  data['data', 'edge', 'data'].edge_index = edge_index\n",
        "  data['data', 'edge', 'data'].edge_label = edge_label\n",
        "\n",
        "  dataset.append(data)\n",
        "\n",
        "  # Save node indices:\n",
        "  '''\n",
        "  data.node_id = Tensor(list(B.nodes()))\n",
        "\n",
        "  # Add the node features and edge indices:\n",
        "  data.x = np.ones(B.number_of_nodes())\n",
        "\n",
        "  data.edge_index = edge_index\n",
        "  data.edge_label = edge_label\n",
        "  data.number_of_nodes =  num_nodes\n",
        "\n",
        "  '''\n",
        "  # Add the node features and edge indices:\n",
        "  #data[\"data\"].x = np.ones(B.number_of_nodes())\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "#data = T.ToUndirected()(data)"
      ],
      "metadata": {
        "id": "YipHUM8gGeIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate fake/debugging dataset\n",
        "sample_data=dataset[0]\n",
        "dataset=[]\n",
        "for i in range(1000):\n",
        "  dataset.append(sample_data)"
      ],
      "metadata": {
        "id": "pzSm8eodBgn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_train_samples = int(0.7*len(dataset))\n",
        "\n",
        "train_dataset = dataset[0:num_train_samples]\n",
        "test_dataset = dataset[num_train_samples:]"
      ],
      "metadata": {
        "id": "yBaEgTqEBZjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load graph object from file\n",
        "#d = pickle.load(open('sampled_data.pickle', 'rb'))"
      ],
      "metadata": {
        "id": "j606YjzWCJGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "uxkDlFTJAaR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_num_nodes=sum([data.num_nodes for data in dataset])"
      ],
      "metadata": {
        "id": "CUGKtBB-Dz4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, 6)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_user[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "\n",
        "        return (edge_feat_user * edge_feat_movie)#.sum(dim=-1)\n",
        "\n",
        "        #ones=torch.ones(edge_feat_user.size(), dtype=torch.long)\n",
        "        #return  (edge_feat_user * ones).sum(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "\n",
        "        #self.movie_lin = torch.nn.Linear(1, hidden_channels)\n",
        "\n",
        "        self.data_emb = torch.nn.Embedding(tot_num_nodes, hidden_channels)\n",
        "        #self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata = (['data'], [('data',\"edge\",'data')]) )\n",
        "\n",
        "        #([\"node_id\"],[\"edge_index\"])\n",
        "\n",
        "        #look here need to change metedata to all possible types\n",
        "\n",
        "        '''\n",
        "(['user', 'movie'],\n",
        " [('user', 'rates', 'movie'), ('movie', 'rev_rates', 'user')])\n",
        "\n",
        "which node representations are learned for each node type in\n",
        "metadata[0], and messages are exchanged between each edge type in\n",
        "metadata[1], as denoted in the \"Modeling Relational Data with Graph Convolutional Networks\" <https://arxiv.org/abs/1703.06103>_ paper:\n",
        "\n",
        "where x_dict and edge_index_dict denote dictionaries that\n",
        "hold node features and edge connectivity information for each node type and\n",
        "edge type, respectively.\n",
        "\n",
        "        '''\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"data\": self.data_emb(data[\"data\"].node_id),\n",
        "          #\"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
        "        }\n",
        "        #print(x_dict)\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"data\"],\n",
        "            data['data', 'edge', 'data'].edge_index\n",
        "            #data['data', 'edge', 'data'].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "#model = GNN(hidden_channels=64)\n",
        "\n",
        "print(model)\n",
        "\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data['data', 'edge', 'data'].edge_label\n",
        "        ground_truth=Tensor([[0., 0., 0., 0., 4., 0.],[0., 0., 0., 0., 4., 0.],[0., 0., 0., 0., 4., 0.],[0., 0., 0., 0., 4., 0.],[0., 0., 0., 0., 4., 0.],[0., 0., 0., 0., 4., 0.]])\n",
        "        # print(np.argmax(pred.detach().numpy()))\n",
        "        # print(pred)\n",
        "        #print(f\"pred = {(ground_truth.type())}\")\n",
        "        #ground_truth*[1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1]\n",
        "        # print((pred.size()))\n",
        "        # print((ground_truth.size()))\n",
        "        # loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "        loss = ((pred - ground_truth) ** 2).mean()\n",
        "        # print(ground_truth)\n",
        "        # print()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "yVC2llbmAaUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f1aa54-fe52-40ac-eeaf-3738a188e3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (data_emb): Embedding(3000, 64)\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (data__edge__data): SAGEConv(64, 6, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Classifier()\n",
            ")\n",
            "Device: 'cpu'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 700/700 [00:03<00:00, 183.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.0134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 700/700 [00:03<00:00, 196.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 700/700 [00:02<00:00, 284.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 700/700 [00:02<00:00, 280.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m=torch.nn.Softmax(6)\n",
        "# pt=Tensor([[0., 0., 1., 0., 0., 0.],[0., 0., 0., 0., 1., 0.],[0., 0., 0., 0., 1., 0.],[0., 0., 0., 0., 1., 0.],[0., 0., 0., 0., 1., 0.],[0., 0., 0., 0., 1., 0.]])\n",
        "# for p in pt: print(torch.argmax(p, dim=0))\n",
        "# print(torch.argmax(pt, dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Ks4_mTD5hp",
        "outputId": "c05cd71a-e19f-4677-cb2b-dff306bf4288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2)\n",
            "tensor(4)\n",
            "tensor(4)\n",
            "tensor(4)\n",
            "tensor(4)\n",
            "tensor(4)\n",
            "tensor([2, 4, 4, 4, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import roc_auc_score\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "right=0\n",
        "c=0\n",
        "for sampled_data in (test_dataset):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        pred=torch.argmax(model(sampled_data), dim=-1)\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(sampled_data[\"data\", \"edge\", \"data\"].edge_label)\n",
        "\n",
        "        for i in range(len(pred)-1):\n",
        "          c+=1\n",
        "          if pred[i]==sampled_data[\"data\", \"edge\", \"data\"].edge_label[i]:\n",
        "            right+=1\n",
        "\n",
        "print(f\"Acc:{right/c*100}%, number of right guess: {right}, tot number of guesses {c}\")\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "pred=[int(p) for p in pred]\n",
        "ground_truth=[int(p) for p in ground_truth]"
      ],
      "metadata": {
        "id": "kzkLoQh6cGFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06938a36-2107-4ce8-82ba-264d9184e4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc:100.0%, number of right guess: 1500, tot number of guesses 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(ground_truth, pred, labels=[0,1,2,3,4])\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Greens');  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "ax.set_xlabel('Predicted labels');\n",
        "ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "x_labels=['LTR', 'RTL', 'MF', 'MB', 'NC']\n",
        "y_labels=x_labels\n",
        "ax.xaxis.set_ticklabels(x_labels); ax.yaxis.set_ticklabels(y_labels);\n",
        "#auc = roc_auc_score(ground_truth, pred, multi_class=\"ovo\")\n",
        "# print()\n",
        "# print(f\"Validation AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "ajLewHP05io0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#not used!!!\n",
        "raise ValueError"
      ],
      "metadata": {
        "id": "zMR4BPO8G2JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try 2\n",
        "from torch_geometric.nn import GraphConv\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(-1, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 9)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        x, edge_index, batch = data[\"data\"].node_id, data[(\"data\", \"edge\", \"data\")].edge_index, data[\"data\"].batch\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        #x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = GNN(hidden_channels=64)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "3RvZ1gJnOoGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xb0SrTACUTyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset"
      ],
      "metadata": {
        "id": "k3RJTT7GAZHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index_dict\n"
      ],
      "metadata": {
        "id": "QgV7JCnL6ulh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=data.metadata()\n",
        "names = metadata[0] + [rel for _, rel, _ in metadata[1]]\n",
        "for name in names:\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "WjFZAht0r5N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " data[\"edge\"].edge_index"
      ],
      "metadata": {
        "id": "GdPJxmmsWeNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "Ak9niIxODTeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7l60br3AaXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxHZP4fQAaZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBTK_1BfAabk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSVmVsohAad4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "#IG[data.edge_index[0][i].item()][2]\n",
        "print(IG[data.edge_index[0][i].item()+1][data.edge_index[1][i].item()+1])"
      ],
      "metadata": {
        "id": "ojqOb25y7o8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=from_networkx(IG)\n",
        "print(data.edge_index)\n",
        "edge_attr=[]\n",
        "for i in range(len(data.edge_index[0])):\n",
        "  print([data.edge_index[0][i]+1][0].item())\n",
        "  t=(IG[data.edge_index[0][i].item()][data.edge_index[1][i].item()])\n",
        "  print(t)\n",
        "  edge_attr.append=t\n",
        "edge_attr\n",
        "#edge_attr= [IG[] for i in data.edge_index]\n",
        "#print(edge_attr)\n",
        "\n",
        "\n",
        "'''\n",
        "edge_attr[i] corresponds to the edge\n",
        "between edge_index[0][i] and edge_index[1][i].\n",
        "'''\n"
      ],
      "metadata": {
        "id": "WoDgpsOAsF3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index=[for i in IG.edges()]\n"
      ],
      "metadata": {
        "id": "WzhVuFifq2Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install dgl\n",
        "\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qBpBTGxGdmKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "q1dvS2D_gIVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "nx.write_edgelist(B,PATH+\"/IA_graph1.csv\",data=[\"label\"], delimiter =\",\" )\n"
      ],
      "metadata": {
        "id": "-YsX82bEJNWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)\n",
        "d=from_networkx(B)\n",
        "edge_index = d.edge_index\n",
        "edge_label = d.label\n",
        "num_nodes = d.num_nodes\n"
      ],
      "metadata": {
        "id": "zSCIwjO7JO1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph=pd.read_csv(PATH + \"/IA_graph1.csv\", header=None, names=[\"src\",'dst','label'])\n",
        "graph"
      ],
      "metadata": {
        "id": "Jn_rx9oQJuEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = np.random.randint(0, 100, 500)\n",
        "dst = np.random.randint(0, 100, 500)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "edge_pred_graph.edata['feature'] = torch.randn(1000, 10)\n",
        "edge_pred_graph.edata['label'] = torch.randn(1000)\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(1000, dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SJpTKrcxq4Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph"
      ],
      "metadata": {
        "id": "dn9qon6OQCQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.edges(data=True)"
      ],
      "metadata": {
        "id": "G_9ix10yRyxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_pred_graph.num_edges()"
      ],
      "metadata": {
        "id": "lOZGUa0oU-cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B=nx.read_edgelist(PATH + \"/IA_graph.csv\", data=True, edgetype=int, nodetype=int, create_using=nx.DiGraph)\n",
        "edge_pred_graph=dgl.from_networkx(B, edge_attrs=[\"label\"])\n",
        "#edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)\n",
        "edge_pred_graph.edata['train_mask']\n"
      ],
      "metadata": {
        "id": "OA_iqIKSQCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(graph))\n",
        "src = graph.src\n",
        "dst = graph.dst\n",
        "num_edges=len(graph)\n",
        "# make it symmetric\n",
        "edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
        "# synthetic node and edge features, as well as edge labels\n",
        "#edge_pred_graph.ndata['feature'] = torch.randn(100, 10)\n",
        "# edge_pred_graph.edata['feature'] = graph.label\n",
        "edge_pred_graph.edata['label'] = graph.label\n",
        "# synthetic train-validation-test splits\n",
        "edge_pred_graph.edata['train_mask'] = torch.zeros(edge_pred_graph.num_edges(), dtype=torch.bool).bernoulli(0.6)"
      ],
      "metadata": {
        "id": "SO5-wmb-Itpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTP9oylYHDpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkCrIptJdbJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNrLbiorddYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWyJQyIzdiYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contruct a two-layer GNN model\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # inputs are features of nodes\n",
        "        print(graph)\n",
        "        print(inputs)\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "import dgl.function as fn\n",
        "class DotProductPredictor(nn.Module):\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, in_features, out_classes):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(in_features * 2, out_classes)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        h_u = edges.src['h']\n",
        "        h_v = edges.dst['h']\n",
        "        score = self.W(torch.cat([h_u, h_v], 1))\n",
        "        return {'score': score}\n",
        "\n",
        "    def forward(self, graph, h):\n",
        "        # h contains the node representations computed from the GNN defined\n",
        "        # in the node classification section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(self.apply_edges)\n",
        "            return graph.edata['score']\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super().__init__()\n",
        "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
        "        self.pred = DotProductPredictor()\n",
        "    def forward(self, g, x):\n",
        "        h = self.sage(g, x)\n",
        "        return self.pred(g, h)\n",
        "\n",
        "from torch import Tensor\n",
        "# node_features = edge_pred_graph.ndata['feature']\n",
        "edge_label = edge_pred_graph.edata['label']\n",
        "train_mask = edge_pred_graph.edata['train_mask']\n",
        "model = Model(1, 20, 10)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "pred = model(edge_pred_graph, Tensor())\n",
        "loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "opt.zero_grad()\n",
        "loss.backward()\n",
        "opt.step()\n",
        "print(loss.item())\n",
        "\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     pred = model(edge_pred_graph, Tensor())\n",
        "#     loss = ((pred[train_mask] - edge_label[train_mask]) ** 2).mean()\n",
        "#     opt.zero_grad()\n",
        "#     loss.backward()\n",
        "#     opt.step()\n",
        "#     print(loss.item())"
      ],
      "metadata": {
        "id": "lX394xGDdkSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpqQ_mRqdFOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class EdgePredictor(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EdgePredictor, self).__init__(aggr='max')  # Use max pooling for message aggregation\n",
        "\n",
        "        self.node_idx = torch.arange(in_channels, dtype=torch.long)\n",
        "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x: Node features\n",
        "        # edge_index: Graph connectivity\n",
        "\n",
        "        # Add self-loops for the message passing\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Calculate the normalized degree for each node\n",
        "        deg = degree(edge_index[0], x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        # Calculate the normalized adjacency matrix\n",
        "        norm = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
        "        edge_index_norm = Tensor((2,200))\n",
        "        print((edge_index / norm).size())\n",
        "        print((edge_index).size())\n",
        "        edge_index_norm = (edge_index / norm).int\n",
        "        return self.propagate(edge_index=edge_index_norm, size=(x.size(0), x.size(0)), x=x)\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        aggr_out = torch.cat([aggr_out, x[self.node_idx]], dim=-1)\n",
        "        aggr_out = F.relu(self.lin(aggr_out))\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Initialize the model\n",
        "model = GNNEdgeClassifier(in_channels=1, hidden_channels=32, out_channels=11)  # 11 classes (0 to 10)\n",
        "\n",
        "# Example data (replace with your own data)\n",
        "x = torch.randn(100, 1)  # Node features (not used in this example)\n",
        "edge_index = torch.randint(0, 100, (2, 200), dtype=torch.long)  # Random edge connectivity\n",
        "edge_labels = torch.randint(0, 11, (200,), dtype=torch.long)  # Random edge labels (0 to 10)\n",
        "\n",
        "# Forward pass\n",
        "predictions = model(x, edge_index)\n",
        "\n",
        "# Calculate loss (replace with your own loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(predictions, edge_labels)\n"
      ],
      "metadata": {
        "id": "7QEW1FPzeS1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPioOvKCZp37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}